# Claude AI Assistant Rules

## Critical Database Safety Rules

### NEVER Reset or Replace Data Without Approval
**CRITICAL**: Before running ANY database reset or data replacement commands, you MUST:

1. ‚úÖ **Verify a recent backup exists** in `/database/backups/`
2. ‚úÖ **Get explicit user approval** by asking the user directly
3. ‚úÖ **Confirm the backup is recent** (within the last 24 hours)
4. ‚úÖ **ALL UPDATES MUST BE INCREMENTAL** - never replace existing work

### Prohibited Commands Without Approval
- `npx supabase db reset`
- `DROP DATABASE`
- `DROP TABLE` (on production tables)
- `TRUNCATE TABLE` (deletes all data)
- Any command that recreates the entire database schema
- Any migration that uses `CASCADE` on core tables
- Any script that imports data with UPSERT/replace behavior
- Any bulk DELETE or UPDATE without WHERE clauses

### UPDATE Philosophy: Incremental Only
**ALL agent updates MUST:**
- ‚úÖ Preserve existing agent data (display_name, description, system_prompt)
- ‚úÖ Only ADD missing fields (evidence, metadata, new columns)
- ‚úÖ Only UPDATE specific fields that need correction
- ‚úÖ Use WHERE clauses to target specific agents
- ‚úÖ Never replace all agents with new imports
- ‚úÖ Never reset status to 'active' without reviewing each agent

### Safe Database Operations
These are allowed without special approval:
- Reading data (`SELECT`, `curl GET requests`)
- Creating new tables (not dropping existing ones)
- Adding columns with `ALTER TABLE ... ADD COLUMN IF NOT EXISTS`
- Creating backups
- Reading migration files
- **UPDATE with WHERE clause** targeting specific agents
- **INSERT** for new agents only (check if exists first)

### Before Any Destructive Database Operation
Ask the user:
```
‚ö†Ô∏è  WARNING: This operation will [describe what will be destroyed]

I found a backup from [date/time]: [backup_file_name]

Do you want me to proceed with this operation?
```

### Backup Protocol
- Always check for backups in `/database/backups/` before destructive operations
- Create a new backup if the latest is older than 1 hour
- Use the backup script: `./scripts/backup-db.sh`

## Project-Specific Rules

### Migration Files
- Migrations are stored in `/supabase/migrations/`
- NOT in `/database/sql/migrations/` (that's just documentation)
- Always create migration files in the correct location

### Schema Cache Issues
- PostgREST caches schema - restart container if needed: `docker restart supabase_rest_VITAL_path`
- Don't immediately assume a field doesn't exist - check the actual database schema first

### Field Validation Before Insert
- Before inserting data, verify fields exist in the database schema
- Don't rely solely on TypeScript types - they may be outdated
- Use metadata/JSONB fields for storing extra data if specific columns don't exist

### Agent Avatar Icons
- **ALWAYS use icon files from `/public/icons/png/avatars/` directory**
- Icon paths should be stored as: `/icons/png/avatars/avatar_XXXX.png`
- DO NOT use emoji characters (üè•, üì±, etc.) for avatars
- There are 200+ avatar icons available (avatar_0001.png through avatar_0200.png)
- Assign avatars based on agent specialization and theme
- When creating or updating agents, map them to appropriate avatar files

### Agent Tier-Appropriate Avatars
- **Tier 1 (Foundational):** avatar_0109-0193
- **Tier 2 (Specialist):** avatar_0200-0314
- **Tier 3 (Ultra-Specialist):** avatar_0400-0449

## Agent Quality Standards

### Evidence-Based Model Selection (MANDATORY)
**Every agent MUST have:**

1. **model_justification** (required, stored in metadata)
   - Why this specific model was chosen
   - What benchmarks/performance metrics support the choice
   - What specific use case requirements drove the decision
   - Format: "Ultra-specialist/Specialist/Foundational requiring [accuracy level] for [domain]. [Model] achieves [X%] on [Benchmark]. Critical/Important for [outcome]."

2. **model_citation** (required, stored in metadata)
   - Academic source (arXiv, DOI, official documentation)
   - Must be accessible and verifiable
   - Standard citations:
     - GPT-4: "OpenAI (2023). GPT-4 Technical Report. arXiv:2303.08774"
     - GPT-3.5-Turbo: "OpenAI (2023). GPT-3.5 Turbo Documentation. https://platform.openai.com/docs/models/gpt-3-5-turbo"
     - Claude 3 Opus: "Anthropic (2024). Claude 3 Model Card. https://www.anthropic.com/news/claude-3-family"
     - BioGPT: "Luo et al. (2022). BioGPT. DOI:10.1093/bib/bbac409"
     - CuratedHealth/meditron70b-qlora-1gpu: "HuggingFace CuratedHealth. Medical fine-tuned 70B model. https://huggingface.co/CuratedHealth/meditron70b-qlora-1gpu"
     - CuratedHealth/Qwen3-8B-SFT-20250917123923: "HuggingFace CuratedHealth. Medical supervised fine-tuned 8B model. https://huggingface.co/CuratedHealth/Qwen3-8B-SFT-20250917123923"
     - CuratedHealth/base_7b: "HuggingFace CuratedHealth. Medical base 7B model. https://huggingface.co/CuratedHealth/base_7b"

3. **Tier-Model Alignment** (enforce strictly)
   ```
   Tier 3 (Ultra-Specialist):
   - Models: GPT-4 ($0.35/query), Claude-3-Opus ($0.40/query), OR CuratedHealth/meditron70b-qlora-1gpu ($0.10/query)
   - Temperature: 0.2
   - Max tokens: 4000
   - Context window: 16000
   - Accuracy target: >95%
   - Use case: Safety-critical, complex reasoning, regulatory compliance, medical diagnosis

   Tier 2 (Specialist):
   - Models: GPT-4 ($0.12/query), GPT-4-Turbo ($0.10/query), CuratedHealth/Qwen3-8B-SFT-20250917123923 ($0.06/query), OR BioGPT ($0.08/query)
   - Temperature: 0.4
   - Max tokens: 3000
   - Context window: 8000
   - Accuracy target: 90-95%
   - Use case: Specialized expertise, domain-specific tasks, medical/clinical workflows

   Tier 1 (Foundational):
   - Models: GPT-3.5-Turbo ($0.015/query), CuratedHealth/base_7b ($0.02/query), OR BioGPT ($0.02/query)
   - Temperature: 0.6
   - Max tokens: 2000
   - Context window: 4000
   - Accuracy target: 85-90%
   - Use case: High-volume, foundational queries, medical triage, escalates to specialists
   ```

### Safety-Critical Agent Requirements
**For agents handling clinical decisions, dosing, drug interactions, or patient safety:**

1. **MUST use Tier-3 models** (GPT-4 or Claude-3-Opus)
   - NO EXCEPTIONS - patient safety is non-negotiable
   - Examples: Dosing Calculator, Drug Interaction Checker, Pediatric Dosing Specialist

2. **MUST have EVIDENCE REQUIREMENTS section** in system_prompt
   - Always cite clinical sources
   - Use evidence hierarchy (Level 1A > 1B > 2A > 2B > 3)
   - Acknowledge uncertainty explicitly
   - Never make medical recommendations without supporting evidence

3. **MUST have safety flags enabled**
   - hipaa_compliant: true
   - audit_trail_enabled: true
   - data_classification: "confidential"

### System Prompt Structure (6-Section Framework)
**All agent system prompts MUST include:**

1. **YOU ARE:** [Specific role and unique positioning]
2. **YOU DO:** [3-7 specific capabilities with measurable outcomes]
3. **YOU NEVER:** [3-5 safety-critical boundaries with rationale]
4. **SUCCESS CRITERIA:** [Measurable performance targets]
5. **WHEN UNSURE:** [Escalation protocol with confidence thresholds]
6. **EVIDENCE REQUIREMENTS:** [For medical/regulated agents - MANDATORY]
   - What sources to cite
   - Evidence level hierarchy
   - When to acknowledge uncertainty
   - Confidence score requirements

### Agent Creation/Update Checklist
Before creating or updating an agent, verify:
- [ ] Tier assignment is appropriate for task complexity
- [ ] Model matches tier requirements
- [ ] model_justification includes specific benchmarks
- [ ] model_citation is accessible (arXiv/DOI/official docs)
- [ ] temperature, max_tokens, context_window are tier-appropriate
- [ ] cost_per_query is calculated correctly
- [ ] System prompt follows 6-section framework
- [ ] Safety flags set for medical/regulated agents
- [ ] Avatar is tier-appropriate (Tier 1: 0109-0193, Tier 2: 0200-0314, Tier 3: 0400-0449)

### Cost Optimization Guidelines
**Before assigning expensive models, ask:**
1. Is >95% accuracy truly REQUIRED? (If no, don't use Tier-3)
2. Is this safety-critical? (If yes, use Tier-3 regardless of cost)
3. Is this biomedical/pharmaceutical? (Consider BioGPT for cost savings)
4. Is this high-volume? (Use Tier-1 models for foundational tasks)

**Cost reference:**
- GPT-4 (Tier-3): $0.35/query (use sparingly, for ultra-specialists)
- Claude-3-Opus (Tier-3): $0.40/query (best reasoning, ultra-specialists)
- GPT-4 (Tier-2): $0.12/query (specialists only)
- CuratedHealth/meditron70b-qlora-1gpu: $0.10/query (medical Tier-3 specialists)
- CuratedHealth/Qwen3-8B-SFT-20250917123923: $0.06/query (medical Tier-2 specialists)
- BioGPT: $0.08/query (biomedical specialists, cost-effective)
- CuratedHealth/base_7b: $0.02/query (medical Tier-1 foundational)
- GPT-3.5-Turbo: $0.015/query (foundational, high-volume)

### Never Do These (Common Mistakes)
- ‚ùå Using Tier-3 models without evidence/justification
- ‚ùå Using GPT-4 for Tier-1 foundational tasks (15x more expensive than GPT-3.5-Turbo)
- ‚ùå Using gpt-4o-mini for Tier-3 ultra-specialists (wrong model tier)
- ‚ùå Skipping model_citation (required for all agents)
- ‚ùå Missing EVIDENCE REQUIREMENTS for medical/clinical agents
- ‚ùå Creating agents without system prompts following the 6-section framework
- ‚ùå Activating agents that haven't been validated

## Phase 2: Standardization Guidelines (Active)

### System Prompt Generation (Batch Processing)

**Current Status:** Phase 1 Complete (9 agents upgraded)
**Next Phase:** Generate unique prompts for remaining 240+ agents

**Batch Strategy:**
1. **Batch 1: Remaining Active Agents (16 agents)** - Add evidence first
2. **Batch 2: Tier-3 Review (80+ agents)** - Audit tier/model alignment
3. **Batch 3: Tier-2 Specialists (170+ agents)** - Systematic evidence addition
4. **Batch 4: Persona Assignment** - Assign all agents to archetypes

**Evidence Template Library:**
```javascript
// Use these templates for batch evidence addition
const EVIDENCE_TEMPLATES = {
  'gpt-4': {
    tier3: {
      justification: 'Ultra-specialist requiring highest accuracy for [DOMAIN]. GPT-4 achieves 86.7% on MedQA (USMLE) and 86.4% on MMLU. Critical for [USE_CASE].',
      citation: 'OpenAI (2023). GPT-4 Technical Report. arXiv:2303.08774',
      temperature: 0.2,
      max_tokens: 4000,
      context_window: 16000,
      cost_per_query: 0.35
    },
    tier2: {
      justification: 'High-accuracy specialist for [DOMAIN]. GPT-4 achieves 86.7% on MedQA (USMLE). Balanced performance for specialist tasks.',
      citation: 'OpenAI (2023). GPT-4 Technical Report. arXiv:2303.08774',
      temperature: 0.4,
      max_tokens: 3000,
      context_window: 8000,
      cost_per_query: 0.12
    }
  },
  'gpt-3.5-turbo': {
    tier1: {
      justification: 'Fast, cost-effective for foundational [DOMAIN] queries. GPT-3.5 Turbo achieves 70% on HumanEval. Ideal for high-volume, low-complexity queries.',
      citation: 'OpenAI (2023). GPT-3.5 Turbo Documentation. https://platform.openai.com/docs/models/gpt-3-5-turbo',
      temperature: 0.6,
      max_tokens: 2000,
      context_window: 4000,
      cost_per_query: 0.015
    }
  },
  'microsoft/biogpt': {
    tier2: {
      justification: 'Cost-effective biomedical specialist. BioGPT achieves F1 0.849 on BC5CDR (chemical-disease relations), 81.2% on PubMedQA. Optimized for [biomedical task].',
      citation: 'Luo et al. (2022). BioGPT: Generative Pre-trained Transformer for Biomedical Text Generation and Mining. DOI:10.1093/bib/bbac409',
      temperature: 0.4,
      max_tokens: 3000,
      context_window: 8000,
      cost_per_query: 0.08
    },
    tier1: {
      justification: 'Fast, cost-effective biomedical responses. BioGPT achieves F1 0.849 on BC5CDR, 81.2% on PubMedQA. Optimized for high-volume foundational queries.',
      citation: 'Luo et al. (2022). BioGPT. DOI:10.1093/bib/bbac409',
      temperature: 0.6,
      max_tokens: 2000,
      context_window: 4000,
      cost_per_query: 0.02
    }
  },
  'claude-3-opus': {
    tier3: {
      justification: 'Best-in-class code generation and complex reasoning. Claude 3 Opus achieves 84.5% pass@1 on HumanEval. Excellent for [use case].',
      citation: 'Anthropic (2024). Claude 3 Model Card. https://www.anthropic.com/news/claude-3-family',
      temperature: 0.2,
      max_tokens: 4000,
      context_window: 16000,
      cost_per_query: 0.40
    }
  }
};
```

### Persona Archetypes (10 Core Types)

**Assign each agent to one of these personas:**

1. **Clinical Expert** - Medical/pharmaceutical specialists
   - Tone: Professional, evidence-focused, compassionate
   - Example: Pharmacist, Clinical Trials Designer

2. **Regulatory Authority** - FDA, EMA, compliance specialists
   - Tone: Formal, compliance-focused, precise
   - Example: FDA Regulatory Strategist, HIPAA Officer

3. **Data Analyst** - Metrics, analytics, insights
   - Tone: Data-driven, quantitative, objective
   - Example: Quality Metrics Analyst, Market Intelligence

4. **Safety Officer** - Risk, adverse events, pharmacovigilance
   - Tone: Cautious, thorough, risk-focused
   - Example: Adverse Event Reporter, Drug Interaction Checker

5. **Research Specialist** - Clinical trials, R&D
   - Tone: Scientific, methodical, evidence-based
   - Example: Clinical Trial Designer, Biostatistician

6. **Business Strategist** - Commercial, market access
   - Tone: Strategic, business-focused, ROI-oriented
   - Example: Reimbursement Strategist, Market Access

7. **Operations Manager** - Manufacturing, supply chain, QA
   - Tone: Process-oriented, efficiency-focused, practical
   - Example: Manufacturing Specialist, Quality Assurance

8. **Compliance Guardian** - Legal, regulatory compliance
   - Tone: Risk-averse, detail-oriented, policy-focused
   - Example: HIPAA Compliance, Data Privacy

9. **Innovation Advisor** - Digital health, technology
   - Tone: Forward-thinking, tech-savvy, solution-oriented
   - Example: Digital Health specialists, AI/ML experts

10. **Patient Advocate** - Patient engagement, education
    - Tone: Accessible, empathetic, health-literacy focused
    - Example: Patient Engagement Platform Advisor

### Batch Processing Scripts (Templates)

**Script Pattern for Evidence Addition:**
```javascript
// scripts/add-evidence-batch-[tier].js
async function addEvidenceToBatch(agents, tier) {
  for (const agent of agents) {
    const template = EVIDENCE_TEMPLATES[agent.model]?.[`tier${tier}`];
    if (!template) continue;

    const justification = template.justification
      .replace('[DOMAIN]', agent.domain_expertise || agent.knowledge_domains[0])
      .replace('[USE_CASE]', agent.description.split('.')[0])
      .replace('[biomedical task]', agent.capabilities[0]);

    await supabase.from('agents').update({
      model: agent.model,
      temperature: template.temperature,
      max_tokens: template.max_tokens,
      context_window: template.context_window,
      cost_per_query: template.cost_per_query,
      metadata: {
        ...agent.metadata,
        model_justification: justification,
        model_citation: template.citation
      }
    }).eq('id', agent.id);
  }
}
```

### Next Actions (Week 2)

**Priority Order:**
1. ‚úÖ Add evidence to 16 remaining active agents (scripts/add-evidence-to-remaining-active.js)
2. ‚úÖ Review 80+ Tier-3 gpt-4o-mini agents (tier/model audit)
3. ‚úÖ Begin Tier-2 evidence addition (170+ agents, batch processing)
4. ‚úÖ Assign persona archetypes to all agents
5. ‚úÖ Generate unique system prompts using persona templates

## General Coding Rules

### File Creation
- NEVER create documentation files unless explicitly requested
- ALWAYS prefer editing existing files over creating new ones
- Only create files that are absolutely necessary

### Communication
- Be concise and direct
- Minimize output tokens while maintaining helpfulness
- No unnecessary preamble or postamble

### Tool Usage
- Use specialized tools (Read, Edit, Write) instead of bash for file operations
- Batch independent tool calls together in a single message
- Use TodoWrite for complex multi-step tasks
