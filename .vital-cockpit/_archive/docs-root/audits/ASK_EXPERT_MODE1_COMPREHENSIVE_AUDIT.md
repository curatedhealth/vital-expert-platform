# ASK EXPERT MODE 1 - COMPREHENSIVE AUDIT REPORT

**Date**: November 18, 2025  
**Auditor**: AI Assistant  
**Scope**: Mode 1 (Chat-Manual) - Backend & Frontend  
**Status**: üî¥ CRITICAL ISSUES FOUND

---

## üìã EXECUTIVE SUMMARY

### What is Mode 1?

**Mode 1: Interactive Manual (Chat-Manual)** is a conversational AI service where:
- User **manually** selects a specific expert agent from 319+ agent catalog
- Engages in **multi-turn conversation** with context retention
- Expert maintains consistent persona throughout the session
- Supports sub-agent spawning for complex queries
- Provides RAG-enhanced responses with citations

### Key Characteristics

| Dimension | Value | Description |
|-----------|-------|-------------|
| **Interaction** | CHAT (Multi-turn) | Back-and-forth dialogue |
| **Selection** | MANUAL | User chooses expert |
| **Response Time** | 15-25 seconds | Target latency |
| **Experts** | 1 selected + sub-agents | Deep agent hierarchy |
| **Tools** | RAG, Web Search, DB | 100+ tool integrations |
| **Context** | 1M+ tokens | Multimodal support |

---

## üî• CRITICAL FINDINGS

### Priority 1: BLOCKER Issues üî¥

#### Issue #1: Backend-Frontend Integration Mismatch
**Severity**: üî¥ CRITICAL  
**Impact**: Mode 1 functionality broken

**Problem**:
- Frontend sends requests to `/api/ask-expert/orchestrate`
- Backend Python has Mode 1 workflow at `/api/mode1/manual`
- TypeScript handler tries to call Python endpoint but routing unclear
- **Result**: Mode 1 requests likely failing

**Evidence**:
```typescript
// Frontend: apps/digital-health-startup/src/app/(app)/ask-expert/page.tsx:851
const response = await fetch('/api/ask-expert/orchestrate', {
  method: 'POST',
  body: JSON.stringify({
    mode: mode, // "manual" for Mode 1
    agentId: agentId,
    message: messageContent,
    ...
  })
});

// TypeScript Handler: apps/digital-health-startup/src/features/chat/services/mode1-manual-interactive.ts:133
const mode1Endpoint = `${API_GATEWAY_URL}/api/mode1/manual`;
const response = await fetch(mode1Endpoint, ...);

// Python Backend: services/ai-engine/src/langgraph_workflows/mode1_manual_query.py
class Mode1ManualQueryWorkflow(BaseWorkflow):
    """Mode 1: Manual Selection + One-Shot Query"""
    # This is designed for one-shot, NOT multi-turn!
```

**Root Cause**:
1. Frontend UI is designed for **multi-turn chat** (Mode 1: Interactive Manual)
2. Python backend implements **one-shot query** (Mode 1: Manual Query)
3. **MISMATCH**: Documentation says "Interactive Manual" but code implements "Manual Query"

---

#### Issue #2: Mode Definition Confusion
**Severity**: üî¥ CRITICAL  
**Impact**: Feature implementation incorrect

**Problem**: The gold standard documentation defines Mode 1 as:
- **Mode 1: Interactive Manual** = CHAT (multi-turn) + MANUAL selection

But the Python implementation says:
```python
"""
Mode 1: Manual Selection + One-Shot Query

User manually selects a specific expert for a single query/response.
This is the simplest mode - choose your expert, ask one question, get one answer.

PRD Specification:
- Interaction: QUERY (One-Shot)  # ‚ùå Should be CHAT (Multi-turn)!
- Selection: MANUAL (User chooses expert)
```

**Correct Mode Matrix**:
```
                    AUTOMATIC Selection  ‚îÇ  MANUAL Selection
QUERY         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
(One-shot)    ‚îÇ  Mode 3: Query-Auto     ‚îÇ  Mode 2: Query-Manual  ‚îÇ
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
CHAT          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
(Multi-turn)  ‚îÇ  Mode 4: Chat-Auto      ‚îÇ  ‚úÖ MODE 1: Chat-Manual‚îÇ
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Current Implementation** (WRONG):
```
                    AUTOMATIC Selection  ‚îÇ  MANUAL Selection
QUERY         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
(One-shot)    ‚îÇ  Mode 3: Query-Auto     ‚îÇ  ‚ùå MODE 1 (WRONG!)   ‚îÇ
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

#### Issue #3: Missing Multi-Turn State Management
**Severity**: üü† HIGH  
**Impact**: Cannot maintain conversation context

**Problem**:
- Python Mode 1 workflow is one-shot (no conversation memory)
- No session persistence between messages
- No conversation history tracking
- No checkpointing enabled

**Evidence**:
```python
# services/ai-engine/src/langgraph_workflows/mode1_manual_query.py:124
super().__init__(
    workflow_name="Mode1_Manual_Query",
    mode=WorkflowMode.MODE_1_MANUAL,
    enable_checkpoints=False  # ‚ùå One-shot doesn't need checkpoints
)
```

**What's Needed**:
- Enable checkpointing for conversation state
- Implement session management
- Add conversation history loading
- Persist messages between turns

---

### Priority 2: Architecture Issues üü°

#### Issue #4: Multiple Duplicate Page Implementations
**Severity**: üü° MEDIUM  
**Impact**: Maintenance overhead, confusion

**Problem**: 66 Ask Expert page files found across 3 apps!

**Files**:
```
apps/digital-health-startup/src/app/(app)/ask-expert/
‚îú‚îÄ‚îÄ page.tsx                              ‚úÖ PRIMARY
‚îú‚îÄ‚îÄ page-modern.tsx                       ‚ùå DELETE
‚îú‚îÄ‚îÄ page-legacy-single-agent.tsx          ‚ùå DELETE
‚îú‚îÄ‚îÄ page-complete.tsx                     ‚ùå DELETE
‚îú‚îÄ‚îÄ page-enhanced.tsx                     ‚ùå DELETE
‚îú‚îÄ‚îÄ page-backup-5mode.tsx                 ‚ùå DELETE
‚îú‚îÄ‚îÄ page-backup-OLD-MODE1-UI.tsx          ‚ùå DELETE
‚îú‚îÄ‚îÄ page-backup-before-gold.tsx           ‚ùå DELETE
‚îú‚îÄ‚îÄ page-gold-standard.tsx                ‚ùì REVIEW
‚îú‚îÄ‚îÄ page-backup-beta-version.tsx          ‚ùå DELETE
‚îú‚îÄ‚îÄ page-backup-20251118-121833.tsx       ‚ùå DELETE
‚îî‚îÄ‚îÄ beta/page.tsx                         ‚ùì CONSOLIDATE/DELETE

apps/vital-system/src/app/(app)/ask-expert/
‚îú‚îÄ‚îÄ [same duplicates]                     ‚ùå DELETE ALL

apps/pharma/src/app/(app)/ask-expert/
‚îú‚îÄ‚îÄ [same duplicates]                     ‚ùå DELETE ALL
```

**Recommendation**: 
- Keep only `page.tsx` in `digital-health-startup`
- Delete all backup and variant files
- Remove duplicate apps folders if unused

---

#### Issue #5: API Routing Confusion
**Severity**: üü° MEDIUM  
**Impact**: Unclear which endpoint handles Mode 1

**Problem**: Multiple API routes with unclear responsibilities

**API Routes Found**:
```
/app/api/ask-expert/
‚îú‚îÄ‚îÄ route.ts                              # Primary? Uses LangGraph
‚îú‚îÄ‚îÄ chat/route.ts                         # Duplicate? Mode config
‚îú‚îÄ‚îÄ orchestrate/route.ts                  # Frontend calls this!
‚îú‚îÄ‚îÄ generate-document/route.ts            # Artifact generation
‚îî‚îÄ‚îÄ mode1/metrics/route.ts                # Metrics only
```

**Current Flow**:
```
Frontend (page.tsx)
  ‚Üì POST /api/ask-expert/orchestrate
  ‚Üì
orchestrate/route.ts ???
  ‚Üì
Mode1ManualInteractiveHandler (TypeScript)
  ‚Üì POST ${API_GATEWAY_URL}/api/mode1/manual
  ‚Üì
API Gateway (Node.js) ???
  ‚Üì Proxy to Python backend?
  ‚Üì
Python AI Engine /api/mode1/manual
  ‚Üì
Mode1ManualQueryWorkflow (Python)
  ‚Üì
Response
```

**Issues**:
1. Too many layers of indirection
2. API Gateway role unclear
3. TypeScript handler duplicates Python functionality
4. No clear error handling path

---

### Priority 3: Implementation Gaps üü†

#### Issue #6: Missing Features from Gold Standard
**Severity**: üü† HIGH  
**Impact**: Product not matching specification

**Missing Features**:

1. **Agent Profile Loading** ‚ùå
   - Gold standard says: Load agent profile, persona, knowledge base
   - Current: No agent profile enrichment visible

2. **Conversation Context Window** ‚ùå
   - Gold standard says: Full conversation history with 1M+ token context
   - Current: No conversation history management

3. **Sub-Agent Spawning** ‚ö†Ô∏è Partially Implemented
   - Gold standard says: Expert can spawn specialist/worker sub-agents
   - Current: Code exists but likely not tested

4. **Tool Execution** ‚ö†Ô∏è Partially Implemented
   - Gold standard says: RAG, Web Search, DB queries, calculators
   - Current: Tool registry exists but integration unclear

5. **Streaming SSE Response** ‚ùå Not Verified
   - Gold standard says: Stream reasoning + tokens via SSE
   - Current: Frontend expects streaming but backend unclear

6. **Cost Tracking** ‚ö†Ô∏è Partially Implemented
   - Gold standard says: Track tokens and cost per message
   - Current: Some tracking code but not end-to-end

7. **Artifacts Generation** ‚ùå Not Integrated
   - Gold standard says: Generate documents, code, charts
   - Current: InlineArtifactGenerator component exists but not connected

---

## üìä BACKEND ANALYSIS

### Python LangGraph Workflow (`mode1_manual_query.py`)

#### ‚úÖ Strengths:
1. **Well-structured LangGraph workflow** with clear nodes
2. **Comprehensive logging** with structlog
3. **Golden Rules compliance** documented
4. **Service injection** for testability
5. **Error handling** at each node
6. **Caching strategy** with cache manager
7. **Human-in-loop validation** for compliance
8. **RAG integration** with UnifiedRAGService
9. **Tool execution** with ToolRegistry
10. **Sub-agent spawning** capability

#### ‚ùå Issues:

1. **Wrong Mode Implementation** üî¥
   - Implements "one-shot query" not "multi-turn chat"
   - No checkpointing enabled
   - No session persistence

2. **Missing Conversation State** üî¥
   ```python
   # Line 124: Checkpoints disabled!
   enable_checkpoints=False  # One-shot doesn't need checkpoints
   ```

3. **No Streaming Implementation** üü†
   - Workflow returns complete response
   - No SSE event generation
   - Frontend expects streaming but backend doesn't stream

4. **Limited Context Retention** üü°
   ```python
   # Line 277-296: Loads history but doesn't loop
   history = await self.memory_manager.get_conversation_history(
       session_id=state['session_id'],
       limit=10  # Last 10 turns only
   )
   ```

5. **Complexity Analysis Too Simple** üü¢
   ```python
   # Line 298-330: Simple heuristics
   complexity_indicators = {
       'multi_step': any(word in query_lower for word in ['step', 'phase', ...]),
       ...
   }
   # Should use LLM for better analysis
   ```

---

### LangGraph Workflow Structure

#### Current Flow:
```
START
  ‚Üì
validate_tenant
  ‚Üì
validate_agent_selection
  ‚Üì
analyze_query_complexity
  ‚Üì
[RAG enabled?] ‚Üí YES ‚Üí rag_retrieval
               ‚Üí NO  ‚Üí skip_rag
  ‚Üì
[Tools enabled?] ‚Üí YES ‚Üí execute_tools
                ‚Üí NO  ‚Üí skip_tools
  ‚Üì
execute_expert_agent
  ‚Üì
format_output
  ‚Üì
END  ‚ùå Should loop back for multi-turn!
```

#### Required Flow for Multi-Turn:
```
START
  ‚Üì
load_session (NEW - load conversation history)
  ‚Üì
validate_tenant
  ‚Üì
validate_agent_selection
  ‚Üì
‚îå‚îÄ‚Üí receive_message (LOOP START)
‚îÇ   ‚Üì
‚îÇ   analyze_query_complexity
‚îÇ   ‚Üì
‚îÇ   [RAG] ‚Üí rag_retrieval / skip_rag
‚îÇ   ‚Üì
‚îÇ   [Tools] ‚Üí execute_tools / skip_tools
‚îÇ   ‚Üì
‚îÇ   execute_expert_agent
‚îÇ   ‚Üì
‚îÇ   format_output
‚îÇ   ‚Üì
‚îÇ   save_message (NEW - persist to DB)
‚îÇ   ‚Üì
‚îÇ   [Continue?] ‚Üí YES ‚Üí ‚îò (loop back)
‚îÇ                NO  ‚Üí END
```

---

## üé® FRONTEND ANALYSIS

### Main Page Component (`page.tsx`)

#### ‚úÖ Strengths:
1. **Clean Claude.ai-inspired UI** - Professional, minimal
2. **Responsive design** with dark mode
3. **Real-time streaming** display
4. **Conversation history** sidebar
5. **Attachment support** (files, images)
6. **Agent selection** integration
7. **RAG domain filtering** UI
8. **Tool selection** UI
9. **Autonomous mode toggle** for future use
10. **Token counter** display

#### ‚ùå Issues:

1. **Wrong API Endpoint** üî¥
   ```typescript
   // Line 851: Calls orchestrate, not mode1
   const response = await fetch('/api/ask-expert/orchestrate', {
     body: JSON.stringify({
       mode: mode, // "manual" for Mode 1
       ...
     })
   });
   ```
   Should call dedicated Mode 1 endpoint

2. **No Session Management** üî¥
   - Doesn't send session_id to backend
   - No session creation on first message
   - No session persistence

3. **Missing Streaming Parsing** üü†
   ```typescript
   // Line 877-1036: Reads response as stream
   // But doesn't parse SSE events properly
   ```

4. **Conversation History Not Sent** üü°
   ```typescript
   // Line 858: Sends history but as simple array
   conversationHistory: conversationContext.map(m => ({
     role: m.role,
     content: m.content
   }))
   // Missing: message IDs, timestamps, metadata
   ```

5. **No Error Boundaries** üü°
   - Component can crash on errors
   - No error boundary wrapper

6. **Huge Component File** üü¢ 
   - 2,263 lines in single file
   - Needs refactoring into smaller components

---

### TypeScript Handler (`mode1-manual-interactive.ts`)

#### ‚úÖ Strengths:
1. **Async generator pattern** for streaming
2. **Metrics tracking** (latency, tokens, cache hits)
3. **Error handling** with try-catch
4. **Logging** with request IDs

#### ‚ùå Issues:

1. **Duplicate Logic** üî¥
   - Reimplements what Python backend should do
   - Why have both TypeScript and Python implementations?

2. **Unclear API Gateway Integration** üî¥
   ```typescript
   // Line 133: Calls API Gateway
   const mode1Endpoint = `${API_GATEWAY_URL}/api/mode1/manual`;
   ```
   - What does API Gateway do?
   - Is it just a proxy?
   - Why not call Python directly?

3. **No Fallback Strategy** üü°
   ```typescript
   // Line 146-157: Error if AI Engine unreachable
   throw new Error(`Failed to connect to AI Engine...`);
   // Should have fallback or retry logic
   ```

---

## üóÑÔ∏è DATABASE SCHEMA ANALYSIS

### Required Tables (from Gold Standard):

#### `ask_expert_sessions`
```sql
CREATE TABLE ask_expert_sessions (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    tenant_id UUID NOT NULL REFERENCES tenants(id) ON DELETE CASCADE,
    user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    agent_id UUID NOT NULL REFERENCES agents(id) ON DELETE CASCADE,
    mode VARCHAR(50) NOT NULL DEFAULT 'mode_1_interactive_manual',
    status VARCHAR(50) NOT NULL DEFAULT 'active',
    metadata JSONB DEFAULT '{}',
    total_messages INTEGER DEFAULT 0,
    total_tokens INTEGER DEFAULT 0,
    total_cost DECIMAL(10, 6) DEFAULT 0.00,
    created_at TIMESTAMPTZ DEFAULT NOW(),
    updated_at TIMESTAMPTZ DEFAULT NOW(),
    ended_at TIMESTAMPTZ
);
```

#### `ask_expert_messages`
```sql
CREATE TABLE ask_expert_messages (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    session_id UUID NOT NULL REFERENCES ask_expert_sessions(id) ON DELETE CASCADE,
    role VARCHAR(20) NOT NULL CHECK (role IN ('user', 'assistant', 'system')),
    content TEXT NOT NULL,
    agent_id UUID REFERENCES agents(id),
    metadata JSONB DEFAULT '{}',
    tokens INTEGER,
    cost DECIMAL(10, 6),
    created_at TIMESTAMPTZ DEFAULT NOW()
);
```

#### ‚ùå Schema Verification Needed:
- Need to verify these tables exist in Supabase
- Need to check indexes
- Need to verify RLS policies

---

## üîß RAG SERVICE INTEGRATION

### Expected RAG Flow (Gold Standard):
```
Query ‚Üí Unified RAG Service ‚Üí Hybrid Search (Semantic + Keyword)
  ‚Üì
Pinecone Vector Search (top_k * 2)
  +
Supabase Full-Text Search (top_k * 2)
  ‚Üì
Hybrid Fusion (RRF - Reciprocal Rank Fusion)
  ‚Üì
Reranking (Cohere or Cross-Encoder)
  ‚Üì
Filter by Similarity Threshold (> 0.7)
  ‚Üì
Return Top K Results
```

### Current Implementation:
```python
# services/ai-engine/src/langgraph_workflows/mode1_manual_query.py:367
rag_results = await self.rag_service.search(
    query=query,
    tenant_id=tenant_id,
    agent_id=selected_agent_id,
    domains=selected_domains if selected_domains else None,
    max_results=max_results
)
```

#### ‚úÖ Strengths:
- Uses UnifiedRAGService
- Supports domain filtering
- Agent-specific retrieval
- Caching enabled

#### ‚ùå Issues:
- No visibility into which RAG strategy is used
- No reranking verification
- No hybrid fusion verification
- Missing from audit report (prior work identified server-only Redis issue)

---

## üõ†Ô∏è TOOL EXECUTION ANALYSIS

### Available Tools (from Gold Standard):
1. **WebSearchTool** - Brave/Google search
2. **DatabaseQueryTool** - Clinical trials, regulatory history
3. **CalculatorTool** - Dosing, statistics, cost analysis
4. **FDALookupTool** - FDA submissions
5. **EMALookupTool** - EMA submissions
6. **PMDALookupTool** - PMDA submissions

### Current Implementation:
```python
# services/ai-engine/src/langgraph_workflows/mode1_manual_query.py:449
tool_results = []
for tool_name in tool_analysis['recommended_tools']:
    tool = self.tool_registry.get_tool(tool_name)
    if tool:
        result = await tool.execute(
            input_data={"query": query},
            context={"tenant_id": tenant_id}
        )
        tool_results.append(...)
```

#### ‚úÖ Strengths:
- Tool registry pattern
- Dynamic tool selection
- Error handling per tool

#### ‚ùå Issues:
- Tool analysis is too simple (keyword matching)
- No tool verification/testing visible
- No tool documentation

---

## üìà PERFORMANCE ANALYSIS

### Target Performance (Gold Standard):
- **First Token**: < 3 seconds
- **Total Response**: 15-25 seconds
- **Streaming**: Progressive token delivery
- **Caching**: 80%+ cache hit rate for repeated queries

### Current Implementation:
- ‚ùì **Unknown** - No performance metrics visible
- ‚ùì **No monitoring** integration found
- ‚ùì **No telemetry** for latency tracking

---

## üîí SECURITY & COMPLIANCE ANALYSIS

### Gold Standard Requirements:
1. **Tenant Isolation** - All queries filtered by tenant_id
2. **RLS Policies** - Row-level security on all tables
3. **HIPAA Compliance** - PHI handling guidelines
4. **GDPR Compliance** - Data retention policies
5. **Human-in-Loop** - High-risk queries require review

### Current Implementation:

#### ‚úÖ Implemented:
```python
# Tenant validation
graph.add_node("validate_tenant", self.validate_tenant_node)

# Human validation
self.compliance_service = compliance_service or ComplianceService(supabase_client)
self.human_validator = human_validator or HumanInLoopValidator()

# Line 620-679: Human review logic
validation_result = await self.human_validator.requires_human_review(
    query=query,
    response=response,
    confidence=confidence,
    ...
)
```

#### ‚ùå Missing:
- RLS policy verification
- HIPAA compliance audit
- Data retention implementation
- Audit logging
- Access control checks

---

## üéØ RECOMMENDATIONS

### Immediate Fixes (This Week)

#### Fix #1: Implement Correct Mode 1 (Multi-Turn Chat) üî¥ CRITICAL
**Effort**: 8-12 hours  
**Priority**: P0 - BLOCKER

**Steps**:
1. **Rename current Mode 1** ‚Üí "Mode 2: Query-Manual (One-Shot)"
2. **Create new Mode 1** ‚Üí "Mode 1: Chat-Manual (Multi-Turn)"
3. **Enable checkpointing** in LangGraph
4. **Add conversation loop** back to receive_message node
5. **Implement session management**:
   - Create session on first message
   - Load history on subsequent messages
   - Update session stats after each response

**Code Changes**:
```python
# New: services/ai-engine/src/langgraph_workflows/mode1_interactive_manual.py

class Mode1InteractiveManualWorkflow(BaseWorkflow):
    """
    Mode 1: Interactive Manual - Multi-Turn Chat
    User selects expert ‚Üí Maintains conversation ‚Üí Context retention
    """
    
    def __init__(self, ...):
        super().__init__(
            workflow_name="Mode1_Interactive_Manual",
            mode=WorkflowMode.MODE_1_INTERACTIVE_MANUAL,
            enable_checkpoints=True  # ‚úÖ Enable for multi-turn!
        )
    
    def build_graph(self) -> StateGraph:
        graph = StateGraph(UnifiedWorkflowState)
        
        # Session management
        graph.add_node("load_session", self.load_session_node)
        graph.add_node("save_message", self.save_message_node)
        
        # Conversation loop
        graph.set_entry_point("load_session")
        graph.add_edge("load_session", "validate_tenant")
        # ... existing nodes ...
        graph.add_edge("format_output", "save_message")
        
        # Loop back or end
        graph.add_conditional_edges(
            "save_message",
            self.should_continue_conversation,
            {
                True: "receive_message",  # Loop back!
                False: END
            }
        )
        
        return graph
```

---

#### Fix #2: Create Dedicated Mode 1 API Endpoint üî¥ CRITICAL
**Effort**: 2-4 hours  
**Priority**: P0 - BLOCKER

**Create**: `/app/api/ask-expert/mode1/chat/route.ts`

```typescript
// app/api/ask-expert/mode1/chat/route.ts

import { NextRequest, NextResponse } from 'next/server';
import { createClient } from '@/lib/supabase/server';

export const runtime = 'nodejs'; // Use Node.js runtime for streaming

export async function POST(request: NextRequest) {
  try {
    const supabase = createClient();
    
    // Get user from session
    const { data: { user } } = await supabase.auth.getUser();
    if (!user) {
      return new Response('Unauthorized', { status: 401 });
    }
    
    const body = await request.json();
    const {
      sessionId,
      agentId,
      message,
      enableRAG = true,
      enableTools = false,
      selectedRagDomains = [],
      requestedTools = [],
    } = body;
    
    // Validate required fields
    if (!agentId || !message) {
      return NextResponse.json(
        { error: 'Missing required fields: agentId, message' },
        { status: 400 }
      );
    }
    
    // Create or load session
    let session;
    if (sessionId) {
      // Load existing session
      const { data, error } = await supabase
        .from('ask_expert_sessions')
        .select('*')
        .eq('id', sessionId)
        .eq('user_id', user.id)
        .single();
      
      if (error) {
        return NextResponse.json({ error: 'Session not found' }, { status: 404 });
      }
      session = data;
    } else {
      // Create new session
      const { data, error } = await supabase
        .from('ask_expert_sessions')
        .insert({
          user_id: user.id,
          tenant_id: user.user_metadata.tenant_id,
          agent_id: agentId,
          mode: 'mode_1_interactive_manual',
          status: 'active',
          metadata: {},
        })
        .select()
        .single();
      
      if (error) {
        return NextResponse.json({ error: 'Failed to create session' }, { status: 500 });
      }
      session = data;
    }
    
    // Call Python AI Engine
    const AI_ENGINE_URL = process.env.AI_ENGINE_URL || 'http://localhost:8000';
    const response = await fetch(`${AI_ENGINE_URL}/api/mode1/interactive`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'x-tenant-id': user.user_metadata.tenant_id,
      },
      body: JSON.stringify({
        session_id: session.id,
        agent_id: agentId,
        message: message,
        enable_rag: enableRAG,
        enable_tools: enableTools,
        selected_rag_domains: selectedRagDomains,
        requested_tools: requestedTools,
        tenant_id: user.user_metadata.tenant_id,
        user_id: user.id,
      }),
    });
    
    if (!response.ok) {
      return NextResponse.json(
        { error: `AI Engine error: ${response.statusText}` },
        { status: response.status }
      );
    }
    
    // Stream response back to client
    return new Response(response.body, {
      headers: {
        'Content-Type': 'text/event-stream',
        'Cache-Control': 'no-cache',
        'Connection': 'keep-alive',
      },
    });
    
  } catch (error) {
    console.error('[Mode1 API] Error:', error);
    return NextResponse.json(
      { error: error instanceof Error ? error.message : 'Internal server error' },
      { status: 500 }
    );
  }
}
```

---

#### Fix #3: Update Frontend to Use New Endpoint üî¥ CRITICAL
**Effort**: 1-2 hours  
**Priority**: P0 - BLOCKER

**Changes**:
```typescript
// apps/digital-health-startup/src/app/(app)/ask-expert/page.tsx

// Line 851: Change from /orchestrate to /mode1/chat
const response = await fetch('/api/ask-expert/mode1/chat', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    sessionId: currentSessionId, // NEW: Track session
    agentId: selectedAgents[0]?.id,
    message: messageContent,
    enableRAG: enableRAG,
    enableTools: enableTools,
    requestedTools: enableTools ? selectedTools : undefined,
    selectedRagDomains: enableRAG ? selectedRagDomains : undefined,
  }),
});
```

---

### Short-Term Improvements (Next 2 Weeks)

#### Improvement #1: Add Session Management to Frontend
**Effort**: 4-6 hours

**Add**:
1. Session ID state tracking
2. Session creation on first message
3. Session metadata display (message count, cost, time)
4. Session management UI (new chat, end session)

---

#### Improvement #2: Implement Proper SSE Streaming
**Effort**: 6-8 hours

**Steps**:
1. Python: Yield SSE events (thinking, token, complete, error)
2. Frontend: Parse SSE events properly
3. Display progressive thinking steps
4. Display tokens as they arrive
5. Handle errors gracefully

---

#### Improvement #3: Add Comprehensive Testing
**Effort**: 12-16 hours

**Tests Needed**:
1. **Unit Tests**: Each LangGraph node
2. **Integration Tests**: Full Mode 1 workflow
3. **E2E Tests**: Frontend ‚Üí Backend ‚Üí Response
4. **Load Tests**: 100 concurrent Mode 1 sessions
5. **Regression Tests**: Verify Mode 1 behavior

---

#### Improvement #4: Refactor Frontend Component
**Effort**: 8-12 hours

**Break down** `page.tsx` (2,263 lines) into:
- `<Mode1ChatInterface>` - Main container
- `<Mode1MessageList>` - Message display
- `<Mode1InputArea>` - Input + attachments
- `<Mode1SessionInfo>` - Session metadata
- `<Mode1SettingsPanel>` - RAG/Tools settings
- `<Mode1ReasoningDisplay>` - Thinking steps

---

### Long-Term Enhancements (Next Month)

#### Enhancement #1: Performance Optimization
**Effort**: 16-24 hours

1. Add Redis caching for agent profiles
2. Implement response caching with semantic similarity
3. Optimize RAG retrieval (parallel searches)
4. Add CDN for static artifacts
5. Implement request debouncing

---

#### Enhancement #2: Advanced Features
**Effort**: 40-60 hours

1. **Branching Conversations**: Allow users to fork conversation at any point
2. **Conversation Templates**: Pre-built conversation starters per agent
3. **Artifact Previews**: Inline preview of generated documents
4. **Voice Input**: Whisper API integration for voice queries
5. **Collaborative Mode**: Multiple users in same session
6. **Agent Handoff**: Transfer conversation to different expert mid-session

---

#### Enhancement #3: Observability & Monitoring
**Effort**: 12-16 hours

1. Add OpenTelemetry tracing
2. Implement Prometheus metrics
3. Create Grafana dashboards
4. Add error tracking (Sentry)
5. Implement usage analytics

---

## üìã TESTING CHECKLIST

### Manual Testing (Mode 1)

- [ ] **Session Creation**: Can create new Mode 1 session
- [ ] **Agent Selection**: Can select expert agent from list
- [ ] **First Message**: Can send first message and get response
- [ ] **Multi-Turn**: Can send follow-up messages with context retention
- [ ] **RAG Retrieval**: Citations appear in response
- [ ] **Tool Execution**: Tools run when needed
- [ ] **Sub-Agent Spawning**: Sub-agents spawn for complex queries
- [ ] **Streaming**: Tokens stream progressively
- [ ] **Reasoning Display**: Thinking steps appear
- [ ] **Error Handling**: Errors display gracefully
- [ ] **Session Persistence**: Session persists across page reloads
- [ ] **Session History**: Can view past messages
- [ ] **Session End**: Can end session properly
- [ ] **Mobile Responsive**: Works on mobile devices
- [ ] **Dark Mode**: Works in dark mode
- [ ] **Attachments**: Can upload files (images, PDFs, etc.)
- [ ] **Artifacts**: Generated artifacts display properly
- [ ] **Cost Tracking**: Token and cost tracking accurate

---

## üéØ SUCCESS CRITERIA

### How do we know Mode 1 is production-ready?

#### Functional Requirements ‚úÖ
- [ ] Multi-turn conversation works end-to-end
- [ ] Session state persists between messages
- [ ] Agent maintains persona consistency
- [ ] RAG retrieval enhances responses with citations
- [ ] Tools execute when appropriate
- [ ] Sub-agents spawn for complex queries
- [ ] Streaming works with SSE
- [ ] Error handling is graceful
- [ ] Sessions are saved to database
- [ ] Session history is retrievable

#### Non-Functional Requirements ‚úÖ
- [ ] First token < 3 seconds
- [ ] Total response < 25 seconds
- [ ] 80%+ cache hit rate for repeated queries
- [ ] No memory leaks during long sessions
- [ ] Mobile responsive
- [ ] Works in dark mode
- [ ] Handles 100 concurrent sessions
- [ ] 99.9% uptime

#### Code Quality ‚úÖ
- [ ] No TypeScript errors
- [ ] No ESLint warnings
- [ ] 80%+ test coverage
- [ ] All tests passing
- [ ] Documentation complete
- [ ] Architecture decision records (ADRs) written

---

## üìä ESTIMATED EFFORT

### Phase 1: Critical Fixes (Week 1)
- Fix #1: Implement correct Mode 1 multi-turn: **8-12 hours**
- Fix #2: Create dedicated API endpoint: **2-4 hours**
- Fix #3: Update frontend integration: **1-2 hours**
- **Total Phase 1**: **11-18 hours** (~2-3 days)

### Phase 2: Short-Term Improvements (Weeks 2-3)
- Improvement #1: Session management: **4-6 hours**
- Improvement #2: SSE streaming: **6-8 hours**
- Improvement #3: Testing: **12-16 hours**
- Improvement #4: Refactoring: **8-12 hours**
- **Total Phase 2**: **30-42 hours** (~1 week)

### Phase 3: Long-Term Enhancements (Weeks 4-6)
- Enhancement #1: Performance: **16-24 hours**
- Enhancement #2: Advanced features: **40-60 hours**
- Enhancement #3: Observability: **12-16 hours**
- **Total Phase 3**: **68-100 hours** (~2-3 weeks)

### **Grand Total**: **109-160 hours** (~3-4 weeks of dedicated work)

---

## üìÅ FILES TO MODIFY

### Backend (Python)
- [ ] **NEW**: `services/ai-engine/src/langgraph_workflows/mode1_interactive_manual.py`
- [ ] **RENAME**: `mode1_manual_query.py` ‚Üí `mode2_manual_query.py`
- [ ] **UPDATE**: `services/ai-engine/src/api/routes/mode1.py`
- [ ] **NEW**: `services/ai-engine/src/api/routes/mode1_interactive.py`

### Frontend (TypeScript/React)
- [ ] **UPDATE**: `apps/digital-health-startup/src/app/(app)/ask-expert/page.tsx`
- [ ] **NEW**: `apps/digital-health-startup/src/app/api/ask-expert/mode1/chat/route.ts`
- [ ] **DELETE**: All backup and variant page files
- [ ] **UPDATE**: `apps/digital-health-startup/src/features/chat/services/mode1-manual-interactive.ts`

### Database
- [ ] **VERIFY**: `ask_expert_sessions` table exists
- [ ] **VERIFY**: `ask_expert_messages` table exists
- [ ] **CREATE**: Migration script if tables missing

### Documentation
- [ ] **UPDATE**: `.claude/vital-expert-docs/04-services/ask-expert/README.md`
- [ ] **UPDATE**: `.claude/vital-expert-docs/04-services/ask-expert/4_MODE_SYSTEM_FINAL.md`
- [ ] **CREATE**: `MODE_1_IMPLEMENTATION_GUIDE.md`
- [ ] **CREATE**: `MODE_1_API_SPECIFICATION.md`
- [ ] **CREATE**: `MODE_1_TESTING_GUIDE.md`

---

## üö® RISK ASSESSMENT

### High Risk üî¥
1. **Breaking Change**: Renaming Mode 1 affects existing usage
   - **Mitigation**: Version API endpoints, support both temporarily
   
2. **Database Migration**: Sessions table might not exist
   - **Mitigation**: Create migration script with rollback

3. **Python Backend Deployment**: Changes require redeployment
   - **Mitigation**: Blue-green deployment strategy

### Medium Risk üü°
1. **API Gateway Changes**: Routing logic might break
   - **Mitigation**: Comprehensive integration testing

2. **Streaming SSE**: Complex to test and debug
   - **Mitigation**: Create SSE testing harness

### Low Risk üü¢
1. **Frontend Changes**: Mostly additive
   - **Mitigation**: Feature flags for gradual rollout

---

## üéâ NEXT STEPS

### Immediate Actions (Today)
1. ‚úÖ **Review this audit** with team
2. ‚úÖ **Prioritize fixes** - Agree on Phase 1 scope
3. ‚úÖ **Create tickets** - Break down work into Jira/GitHub issues
4. ‚úÖ **Assign owners** - Who implements what?

### This Week
1. ‚úÖ **Implement Critical Fixes** (Phase 1)
   - Day 1-2: Backend multi-turn implementation
   - Day 2-3: API endpoint creation
   - Day 3: Frontend integration
   
2. ‚úÖ **Testing**
   - Day 4: Manual testing
   - Day 5: Fix bugs, polish

3. ‚úÖ **Deploy to Staging**
   - Friday: Deploy and smoke test

### Next Week
1. ‚úÖ **Production Deployment** (if staging successful)
2. ‚úÖ **Monitor Metrics**
3. ‚úÖ **Start Phase 2** (Short-term improvements)

---

## üìö APPENDIX

### A. Mode Definitions (Correct)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  ASK EXPERT MODE MATRIX                      ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                              ‚îÇ
‚îÇ              AUTOMATIC Selection  ‚îÇ  MANUAL Selection        ‚îÇ
‚îÇ              (System Picks)       ‚îÇ  (User Picks)           ‚îÇ
‚îÇ                                   ‚îÇ                          ‚îÇ
‚îÇ QUERY    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ
‚îÇ (One)    ‚îÇ  Mode 3: Query-Auto  ‚îÇ  Mode 2: Query-Manual  ‚îÇ‚îÇ
‚îÇ Shot     ‚îÇ  ‚Ä¢ System picks      ‚îÇ  ‚Ä¢ User picks expert   ‚îÇ‚îÇ
‚îÇ          ‚îÇ  ‚Ä¢ One Q&A           ‚îÇ  ‚Ä¢ One Q&A             ‚îÇ‚îÇ
‚îÇ          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ
‚îÇ                                   ‚îÇ                          ‚îÇ
‚îÇ CHAT     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ
‚îÇ (Multi-  ‚îÇ  Mode 4: Chat-Auto   ‚îÇ  Mode 1: Chat-Manual   ‚îÇ‚îÇ
‚îÇ  Turn)   ‚îÇ  ‚Ä¢ System picks      ‚îÇ  ‚Ä¢ User picks expert   ‚îÇ‚îÇ
‚îÇ          ‚îÇ  ‚Ä¢ Multi-turn        ‚îÇ  ‚Ä¢ Multi-turn          ‚îÇ‚îÇ
‚îÇ          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ
‚îÇ                                                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### B. API Endpoints (Proposed)

```
/api/ask-expert/
‚îú‚îÄ‚îÄ mode1/
‚îÇ   ‚îú‚îÄ‚îÄ chat              POST    Multi-turn conversation
‚îÇ   ‚îú‚îÄ‚îÄ sessions          GET     List user sessions
‚îÇ   ‚îú‚îÄ‚îÄ sessions/:id      GET     Get session details
‚îÇ   ‚îú‚îÄ‚îÄ sessions/:id      DELETE  End session
‚îÇ   ‚îî‚îÄ‚îÄ metrics           GET     Mode 1 metrics
‚îÇ
‚îú‚îÄ‚îÄ mode2/
‚îÇ   ‚îî‚îÄ‚îÄ query             POST    One-shot manual query
‚îÇ
‚îú‚îÄ‚îÄ mode3/
‚îÇ   ‚îî‚îÄ‚îÄ query             POST    One-shot auto query
‚îÇ
‚îú‚îÄ‚îÄ mode4/
‚îÇ   ‚îî‚îÄ‚îÄ chat              POST    Multi-turn auto chat
‚îÇ
‚îî‚îÄ‚îÄ agents/
    ‚îú‚îÄ‚îÄ list              GET     List available agents
    ‚îî‚îÄ‚îÄ select            POST    AI agent selection
```

### C. Database Schema (Full)

```sql
-- Sessions table
CREATE TABLE ask_expert_sessions (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    tenant_id UUID NOT NULL REFERENCES tenants(id) ON DELETE CASCADE,
    user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    agent_id UUID NOT NULL REFERENCES agents(id) ON DELETE CASCADE,
    mode VARCHAR(50) NOT NULL DEFAULT 'mode_1_interactive_manual',
    status VARCHAR(50) NOT NULL DEFAULT 'active' CHECK (status IN ('active', 'ended', 'archived')),
    title VARCHAR(255),
    metadata JSONB DEFAULT '{}',
    total_messages INTEGER DEFAULT 0,
    total_tokens INTEGER DEFAULT 0,
    total_cost DECIMAL(10, 6) DEFAULT 0.00,
    created_at TIMESTAMPTZ DEFAULT NOW(),
    updated_at TIMESTAMPTZ DEFAULT NOW(),
    ended_at TIMESTAMPTZ
);

-- Messages table
CREATE TABLE ask_expert_messages (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    session_id UUID NOT NULL REFERENCES ask_expert_sessions(id) ON DELETE CASCADE,
    role VARCHAR(20) NOT NULL CHECK (role IN ('user', 'assistant', 'system')),
    content TEXT NOT NULL,
    agent_id UUID REFERENCES agents(id),
    metadata JSONB DEFAULT '{}',
    tokens INTEGER,
    cost DECIMAL(10, 6),
    created_at TIMESTAMPTZ DEFAULT NOW()
);

-- Indexes
CREATE INDEX idx_sessions_tenant ON ask_expert_sessions(tenant_id);
CREATE INDEX idx_sessions_user ON ask_expert_sessions(user_id);
CREATE INDEX idx_sessions_agent ON ask_expert_sessions(agent_id);
CREATE INDEX idx_sessions_status ON ask_expert_sessions(status);
CREATE INDEX idx_sessions_mode ON ask_expert_sessions(mode);
CREATE INDEX idx_messages_session ON ask_expert_messages(session_id);
CREATE INDEX idx_messages_created ON ask_expert_messages(created_at DESC);

-- Row Level Security
ALTER TABLE ask_expert_sessions ENABLE ROW LEVEL SECURITY;
ALTER TABLE ask_expert_messages ENABLE ROW LEVEL SECURITY;

-- RLS Policies
CREATE POLICY "Users can view their own sessions"
    ON ask_expert_sessions FOR SELECT
    USING (user_id = auth.uid() OR tenant_id IN (
        SELECT tenant_id FROM user_tenants WHERE user_id = auth.uid()
    ));

CREATE POLICY "Users can create sessions"
    ON ask_expert_sessions FOR INSERT
    WITH CHECK (user_id = auth.uid());

CREATE POLICY "Users can update their sessions"
    ON ask_expert_sessions FOR UPDATE
    USING (user_id = auth.uid());

CREATE POLICY "Users can view their session messages"
    ON ask_expert_messages FOR SELECT
    USING (session_id IN (
        SELECT id FROM ask_expert_sessions WHERE user_id = auth.uid()
    ));

CREATE POLICY "Users can create messages in their sessions"
    ON ask_expert_messages FOR INSERT
    WITH CHECK (session_id IN (
        SELECT id FROM ask_expert_sessions WHERE user_id = auth.uid()
    ));
```

---

**END OF AUDIT REPORT**

Ready to proceed with fixes? Let's prioritize and get Mode 1 working properly! üöÄ


