# ðŸš€ Python AI Engine Deployment Guide

## âœ… Status: READY TO DEPLOY

The Python AI Engine has been configured with **shared framework endpoints** for LangGraph, AutoGen (your CuratedHealth fork!), and CrewAI.

---

## ðŸ“‹ What Was Done

### 1. âœ… Frameworks Router Created
**File**: `services/ai-engine/app/api/frameworks.py`

**Endpoints**:
- `GET /frameworks/info` - Framework information
- `POST /frameworks/langgraph/execute` - Execute LangGraph workflow
- `POST /frameworks/autogen/execute` - Execute AutoGen workflow (YOUR FORK!)
- `POST /frameworks/crewai/execute` - Execute CrewAI workflow

### 2. âœ… Router Registered in Main App
**File**: `services/ai-engine/src/main.py`

Added:
```python
# Include Shared Framework routes (LangGraph, AutoGen, CrewAI)
try:
    import sys
    sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'app'))
    from api.frameworks import router as frameworks_router
    app.include_router(frameworks_router, prefix="", tags=["frameworks"])
    logger.info("âœ… Shared Framework routes registered (LangGraph, AutoGen, CrewAI)")
except ImportError as e:
    logger.warning(f"âš ï¸  Could not import frameworks router: {e}")
    logger.warning("   Continuing without shared framework endpoints")
```

### 3. âœ… Dependencies Configured
**File**: `services/ai-engine/langgraph-requirements.txt`

Includes:
```
# AutoGen - CuratedHealth Fork
git+https://github.com/curatedhealth/autogen.git@main

# LangChain/LangGraph
langgraph>=0.0.40

# CrewAI
crewai>=0.28.0
```

### 4. âœ… Deployment Scripts Created
- `deploy-frameworks.sh` - Automated deployment script
- `test-frameworks.py` - Comprehensive test suite

---

## ðŸš€ Quick Start (5 Minutes)

### Step 1: Deploy the Engine

```bash
cd services/ai-engine
./deploy-frameworks.sh
```

This will:
1. âœ… Create virtual environment
2. âœ… Install dependencies (including your AutoGen fork)
3. âœ… Verify installations
4. âœ… Start the server on port 8000

### Step 2: Test the Endpoints

**In a new terminal**:
```bash
cd services/ai-engine
source venv/bin/activate
python3 test-frameworks.py
```

This will test:
- âœ… Health check
- âœ… Frameworks info
- âœ… AutoGen endpoint (your fork!)
- âœ… LangGraph endpoint
- âœ… CrewAI endpoint

---

## ðŸ“– Manual Deployment Steps

### 1. Navigate to AI Engine Directory
```bash
cd services/ai-engine
```

### 2. Create Virtual Environment
```bash
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

### 3. Install Dependencies
```bash
pip install --upgrade pip
pip install -r langgraph-requirements.txt
```

This installs:
- LangGraph
- **Your CuratedHealth AutoGen fork** (`git+https://github.com/curatedhealth/autogen.git@main`)
- CrewAI
- All other dependencies

### 4. Verify AutoGen Fork
```bash
python3 << 'EOF'
import autogen
print(f"âœ… AutoGen installed from: {autogen.__file__}")
print("âœ… CuratedHealth fork loaded successfully!")
EOF
```

### 5. Start the Server
```bash
python3 start.py
```

Or with custom port:
```bash
PORT=8001 python3 start.py
```

### 6. Verify Server is Running
```bash
curl http://localhost:8000/health
curl http://localhost:8000/frameworks/info
```

---

## ðŸ§ª Testing the Deployment

### Test 1: Health Check
```bash
curl http://localhost:8000/health
```

**Expected**:
```json
{
  "status": "healthy",
  "timestamp": "2025-11-03T..."
}
```

### Test 2: Frameworks Info
```bash
curl http://localhost:8000/frameworks/info
```

**Expected**:
```json
{
  "frameworks": [
    {
      "id": "langgraph",
      "name": "LangGraph",
      "version": "0.0.40",
      "bestFor": ["Sequential workflows", "State management", "Conditional routing"]
    },
    {
      "id": "autogen",
      "name": "AutoGen (CuratedHealth)",
      "version": "0.2.0",
      "fork": "https://github.com/curatedhealth/autogen",
      "bestFor": ["Multi-agent conversations", "Consensus building", "Debate"]
    },
    {
      "id": "crewai",
      "name": "CrewAI",
      "version": "0.28.0",
      "bestFor": ["Task delegation", "Hierarchical workflows", "Role-based agents"]
    }
  ]
}
```

### Test 3: AutoGen Endpoint (YOUR FORK!)
```bash
curl -X POST http://localhost:8000/frameworks/autogen/execute \
  -H "Content-Type: application/json" \
  -d '{
    "workflow": {
      "framework": "autogen",
      "mode": "conversational",
      "agents": [
        {
          "id": "expert1",
          "role": "Healthcare CEO",
          "systemPrompt": "You are a Healthcare CEO.",
          "model": "gpt-4o"
        },
        {
          "id": "expert2",
          "role": "Healthcare CFO",
          "systemPrompt": "You are a Healthcare CFO.",
          "model": "gpt-4o"
        }
      ]
    },
    "input": {
      "message": "What are the top 3 priorities this quarter?"
    }
  }'
```

**Expected**:
```json
{
  "success": true,
  "framework": "autogen",
  "outputs": {
    "messages": [...],
    "result": {...}
  },
  "metadata": {
    "duration": 5.2,
    "tokensUsed": 1234,
    "agentsInvolved": ["expert1", "expert2"]
  }
}
```

### Test 4: Run Full Test Suite
```bash
python3 test-frameworks.py
```

---

## ðŸ”§ Configuration

### Environment Variables

Create a `.env` file in `services/ai-engine`:

```bash
# Required
OPENAI_API_KEY=sk-...

# Optional
PORT=8000
LOG_LEVEL=info
SUPABASE_URL=https://...
SUPABASE_ANON_KEY=...
```

### Framework-Specific Settings

Edit `app/api/frameworks.py` to customize:
- Model defaults
- Temperature settings
- Timeout values
- Max tokens

---

## ðŸ› Troubleshooting

### Issue 1: Import Error - frameworks router not found

**Error**:
```
âš ï¸ Could not import frameworks router: No module named 'api.frameworks'
```

**Fix**:
```bash
# Verify file exists
ls -la app/api/frameworks.py

# If missing, check that frameworks.py was created in the right location
```

### Issue 2: AutoGen not installed

**Error**:
```
ModuleNotFoundError: No module named 'autogen'
```

**Fix**:
```bash
# Reinstall from langgraph-requirements.txt
pip install -r langgraph-requirements.txt

# Or install directly
pip install git+https://github.com/curatedhealth/autogen.git@main
```

### Issue 3: Port already in use

**Error**:
```
ERROR: [Errno 48] Address already in use
```

**Fix**:
```bash
# Use a different port
PORT=8001 python3 start.py

# Or kill the process using port 8000
lsof -ti:8000 | xargs kill -9
```

### Issue 4: OpenAI API key not set

**Error**:
```
openai.error.AuthenticationError: No API key provided
```

**Fix**:
```bash
# Set in .env file
echo "OPENAI_API_KEY=sk-..." >> .env

# Or export temporarily
export OPENAI_API_KEY=sk-...
```

---

## ðŸ“Š Monitoring

### Server Logs
```bash
# View real-time logs
tail -f server.log

# View last 100 lines
tail -n 100 server.log
```

### Health Check
```bash
# Check server health every 5 seconds
watch -n 5 "curl -s http://localhost:8000/health | jq ."
```

### Framework Metrics
```bash
# Get framework info
curl http://localhost:8000/frameworks/info | jq .
```

---

## ðŸŽ¯ Next Steps

### 1. âœ… Deploy Python AI Engine (Current Step)
```bash
cd services/ai-engine
./deploy-frameworks.sh
```

### 2. Test with Frontend
Update your frontend to call the new endpoints:

```typescript
// File: apps/digital-health-startup/src/app/api/frameworks/execute/route.ts

export async function POST(req: NextRequest) {
  const body = await req.json();
  
  // Route to Python AI Engine
  const response = await fetch('http://localhost:8000/frameworks/autogen/execute', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify(body),
  });
  
  return NextResponse.json(await response.json());
}
```

### 3. Test Ask Panel with Shared Orchestrator
```typescript
import { executePanel } from '@/lib/orchestration';

const result = await executePanel(experts, question, {
  mode: 'conversational',  // Uses AutoGen (your fork!)
  source: 'ask-panel',
});
```

---

## âœ… Deployment Checklist

- [ ] Virtual environment created
- [ ] Dependencies installed (including AutoGen fork)
- [ ] AutoGen fork verified
- [ ] Server starts without errors
- [ ] Health check passes
- [ ] Frameworks info endpoint works
- [ ] AutoGen endpoint tested (your fork!)
- [ ] LangGraph endpoint tested
- [ ] CrewAI endpoint tested
- [ ] Frontend can call endpoints
- [ ] Ask Panel uses shared orchestrator

---

## ðŸŽ‰ Success Criteria

**Your deployment is successful when**:
1. âœ… Server starts on port 8000
2. âœ… `/health` returns 200
3. âœ… `/frameworks/info` lists all 3 frameworks
4. âœ… AutoGen endpoint executes (uses YOUR fork!)
5. âœ… Test suite passes (all tests green)
6. âœ… Frontend can call endpoints
7. âœ… Ask Panel works with shared orchestrator

---

## ðŸ“š Documentation

- **Architecture**: See `SHARED_FRAMEWORK_ARCHITECTURE.md`
- **AutoGen Fork**: See `AUTOGEN_FORK_INTEGRATION.md`
- **API Reference**: See `app/api/frameworks.py`
- **Frontend Integration**: See `apps/digital-health-startup/src/lib/orchestration/multi-framework-orchestrator.ts`

---

## ðŸš€ Quick Commands

```bash
# Deploy
./deploy-frameworks.sh

# Test
python3 test-frameworks.py

# Manual start
python3 start.py

# Check logs
tail -f server.log

# Stop server
# Press Ctrl+C
```

---

## ðŸŽ¯ Status

**âœ… READY TO DEPLOY**

Your Python AI Engine is configured with:
- âœ… Shared framework endpoints
- âœ… Your CuratedHealth AutoGen fork
- âœ… LangGraph support
- âœ… CrewAI support
- âœ… Automated deployment scripts
- âœ… Comprehensive test suite

**Next**: Run `./deploy-frameworks.sh` to start! ðŸš€

