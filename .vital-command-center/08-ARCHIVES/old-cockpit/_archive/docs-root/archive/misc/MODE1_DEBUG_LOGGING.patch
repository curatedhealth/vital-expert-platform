--- a/apps/digital-health-startup/src/app/(app)/ask-expert/page.tsx
+++ b/apps/digital-health-startup/src/app/(app)/ask-expert/page.tsx
@@ -1240,6 +1240,11 @@
                       if (typeof chunk.confidence === 'number') {
                         confidence = chunk.confidence;
                       }
                     } else if (chunk.type === 'rag_sources') {
+                      console.log('üì• [DEBUG] Received rag_sources event:', {
+                        hasChunk: !!chunk,
+                        sourcesCount: chunk.sources?.length || 0,
+                        firstSource: chunk.sources?.[0]
+                      });
+                      
                       const incomingSources = Array.isArray(chunk.sources) ? chunk.sources : [];
                       sources = incomingSources.map((source: any, idx: number) => ({
                         number: typeof source.number === 'string' ? parseInt(source.number, 10) : source.number ?? idx + 1,
@@ -1257,6 +1262,11 @@
                         reliabilityScore: source.reliabilityScore,
                         lastUpdated: source.lastUpdated
                       }));
+                      
+                      console.log('üìä [DEBUG] After mapping sources:', {
+                        sourcesLength: sources.length,
+                        firstMapped: sources[0]
+                      });
                       updateStreamingMeta();
                     } else if (chunk.type === 'langgraph_reasoning') {
                       // Handle real-time AI reasoning from LangGraph
@@ -1937,6 +1947,14 @@
       const finalSources = streamingMeta?.sources || sources || [];
       const finalReasoning = streamingMeta?.reasoning || reasoning || [];
+      
+      console.log('‚úÖ [DEBUG] Final Message Sources Check:', {
+        streamingMetaSources: streamingMeta?.sources?.length || 0,
+        localSources: sources.length,
+        finalSourcesLength: finalSources.length,
+        firstFinalSource: finalSources[0]
+      });
+      
       // ‚úÖ FIX: Merge backend ragSummary data with local data
       const finalRagSummary = {
         totalSources: finalSources.length,  // ‚úÖ Correct count from final sources

--- a/apps/digital-health-startup/src/features/ask-expert/components/EnhancedMessageDisplay.tsx
+++ b/apps/digital-health-startup/src/features/ask-expert/components/EnhancedMessageDisplay.tsx
@@ -913,11 +913,24 @@
             {/* Reasoning Section - Shadcn AI Component */}
             {!isUser && (metadata?.reasoning || metadata?.workflowSteps || metadata?.reasoningSteps) && (
               <Reasoning 
                 isStreaming={isStreaming} 
                 defaultOpen={true}
                 open={showReasoning}
                 onOpenChange={setShowReasoning}
                 className="mt-3"
               >
                 <ReasoningTrigger 
                   title="AI Reasoning"
-                  onClick={() => setShowReasoning(!showReasoning)}
                 />
                 <ReasoningContent>

@@ -1185,6 +1198,12 @@
             )}
 
             {!isUser && ragSummary && metadata?.sources && metadata.sources.length > 0 && (
+              {console.log('üîç [DEBUG] Rendering References:', {
+                sourcesCount: metadata.sources.length,
+                ragSummary: ragSummary,
+                firstSource: metadata.sources[0]
+              })}
+              
               <>
                 {/* ‚úÖ Chicago-style citations list with badges */}
                 <div className="mt-4 space-y-2">

--- a/services/ai-engine/src/langgraph_workflows/mode1_manual_workflow.py
+++ b/services/ai-engine/src/langgraph_workflows/mode1_manual_workflow.py
@@ -794,12 +794,21 @@
         
         # Emit final sources and summary via custom stream so frontend can render immediately
         if final_citations:
+            logger.info(
+                "üì§ [DEBUG] Emitting rag_sources event",
+                citations_count=len(final_citations),
+                first_citation=final_citations[0] if final_citations else None
+            )
+            
             try:
                 writer({
                     "type": "rag_sources",
                     "sources": final_citations,
                     "total": len(final_citations),
                     "domains": state.get('selected_rag_domains', []),
                     "strategy": state.get('retrieval_strategy', 'hybrid'),
                     "cacheHit": state.get('rag_cache_hit', False),
                     "retrievalTimeMs": state.get('retrieval_time_ms')
                 })
+                logger.info("‚úÖ [DEBUG] rag_sources event emitted successfully")
             except Exception as stream_error:
                 logger.warning("‚ö†Ô∏è Failed to emit rag_sources event", error=str(stream_error))

